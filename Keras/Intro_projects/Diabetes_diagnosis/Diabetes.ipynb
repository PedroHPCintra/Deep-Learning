{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnóstico de Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diabetes é uma doença é uma doença metabólica crônica, caracterizada pelo grau elevado de glicose (açucar) no sangue, causando danos severos ao coração, às veias, olhos e nervos, segundo a Organização Mundial da Saúde (OMS). Ainda de acordo com a OMS, 422 milhões de pessoas no mundo possuem diabetes e 1.6 milhões morrem todos os anos devido à diabetes.\n",
    "\n",
    "Neste programa, o computador aprenderá a reconhecer os padrões importantes que caracterizam o diagnóstico de diabetes. Para isso, utilizamos uma série de dados organizados em uma tabela com vários indicadores de risco de diabetes, incluindo idade, pressão sanguínea, nível de glicose no sangue, etc.\n",
    "\n",
    "| Nº gravidez | Glicose (mg/dL) | Pressão Sanguínea (mmHg) | Espessura da pele ($\\mu$m) | Insulina | BMI | DPF | Idade | Resultado\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 6 | 148 | 72 | 35 | 0 | 33.6 | 627 | 50 | Sim |\n",
    "|1 | 85 | 66 | 29 | 0 | 26.6 | 351 | 31 | Não |\n",
    "\n",
    "Para o programa, nossa tabela de dados vai identificar \"sim\" como 1, e \"não\" como 0.\n",
    "\n",
    "Começaremos o programa importanto os pacotes importantes para a criação da rede neural, treino, teste e avaliação dela. Para este programa, usamos o pacote \"pandas\" para importar nossos dados, o \"numpy\" para utilizar funções e conceitos matemáticos, o \"matplotlib\" para criar os gráficos necessários, o \"keras\" para importar bibliotecas que criam as redes neurais e as camadas delas e por ultimo o \"scipy\" para realizar integrais que eventualmente serão utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com nossos pacotes prontos, precisamos começar importanto nossos dados com a biblioteca do \"pandas\". Para facilitar, já iremos transformar estes dados em um array numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\"https://raw.githubusercontent.com/PedroHPCintra//Deep-Learning/master/Pima-Diabetes.csv\")\n",
    "\n",
    "#Transformar os dados em um array\n",
    "Data = np.array(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfeito, agora precisamos dividir estes dados em treino e teste, ou seja, parte destes dados serão usados para treinar a rede neural a identificar os padrões relevantes e outra parte dos dados será usada para testar a acurácia da nossa rede neural após o treino. Aqui, as 8 primeiras colunas dos nossos dados serão os parâmetros de avaliação e a 9º coluna compõe o gabarito. Também iremos dividir o tamanho da tabela da seguinte forma, 80% dos dados serão usados para treinar a rede neural e 20% para testa-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data[:np.int(0.8*len(Data)),:8] #Train data\n",
    "train_label = Data[:np.int(0.8*len(Data)),8] #Gabarito do treino\n",
    "\n",
    "test_data = Data[np.int(0.8*len(Data)):,:8] #Dados de teste\n",
    "test_label = Data[np.int(0.8*len(Data)):,8] #Gabarito do teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudo ótimo até aqui, seguindo a diante, nossa próxima tarefa é construir a rede neural que irá avaliar os dados. O pacote \"models\" dentro do \"keras\" irá definir para nós o tipo de rede neural que construiremos enquanto o pacote \"layers\" nos permite definir cada camada da rede neural. Aqui usaremos uma rede neural sequencial, ou seja, as camadas estão organizadas em sequência. Usaremos camadas de rede densa, o que quer dizer que todos os neurônios da camada estão conectados à camada anterior. Nossa função de ativação do neurônio será uma sigmoide!\n",
    "\n",
    "Além disso, também incluiremos camadas de dropout entre as camadas densas para evitar um overfitting. O dropout irá excluir aleatoriamente alguns neurônios, impedindo que os padrões aprendidos pela rede neural sejam específicos demais para os dados de treino. Basicamente, nós perdemos parte da informação para que nosso padrão encontrado seja generalizado o suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(1000, activation = 'sigmoid', input_shape = (8,)))\n",
    "network.add(layers.Dropout(0.3))\n",
    "network.add(layers.Dense(500, activation = 'sigmoid'))\n",
    "network.add(layers.Dropout(0.2))\n",
    "network.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "network.compile(optimizer = 'adam',\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora treinar a rede neural com os dados. Devemos determinar agora as épocas de treino. Na primeira época a rede neural atribuirá algumas condições iniciais para os pesos de cada uma das 8 variáveis, após o treino a rede irá encontrar um valor para os pesos que será mais adequado para o modelo. Na época seguinte, o programa irá avaliar os dados novamente, mas as condições iniciais serão aquelas que ele anterioremente achou como sendo mais adequadas. E assim por diante até ele terminar todas as épocas que determinamos.\n",
    "\n",
    "Outro parâmetro importante é o \"batch_size\" que vai determinar a taxa de atualização dos pesos dados para cada entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "605/605 [==============================] - 3s 5ms/step - loss: 0.7636 - accuracy: 0.4347\n",
      "Epoch 2/100\n",
      "605/605 [==============================] - 0s 182us/step - loss: 1.0461 - accuracy: 0.6545\n",
      "Epoch 3/100\n",
      "605/605 [==============================] - 0s 89us/step - loss: 0.8289 - accuracy: 0.6545\n",
      "Epoch 4/100\n",
      "605/605 [==============================] - 0s 101us/step - loss: 0.6773 - accuracy: 0.5686\n",
      "Epoch 5/100\n",
      "605/605 [==============================] - 0s 104us/step - loss: 0.8524 - accuracy: 0.4050\n",
      "Epoch 6/100\n",
      "605/605 [==============================] - 0s 125us/step - loss: 0.6360 - accuracy: 0.6430\n",
      "Epoch 7/100\n",
      "605/605 [==============================] - 0s 166us/step - loss: 0.7019 - accuracy: 0.6545\n",
      "Epoch 8/100\n",
      "605/605 [==============================] - 0s 173us/step - loss: 0.7515 - accuracy: 0.6562\n",
      "Epoch 9/100\n",
      "605/605 [==============================] - 0s 107us/step - loss: 0.6532 - accuracy: 0.6612\n",
      "Epoch 10/100\n",
      "605/605 [==============================] - 0s 159us/step - loss: 0.6107 - accuracy: 0.6628\n",
      "Epoch 11/100\n",
      "605/605 [==============================] - 0s 124us/step - loss: 0.6804 - accuracy: 0.6050\n",
      "Epoch 12/100\n",
      "605/605 [==============================] - 0s 134us/step - loss: 0.6326 - accuracy: 0.6612\n",
      "Epoch 13/100\n",
      "605/605 [==============================] - 0s 152us/step - loss: 0.5800 - accuracy: 0.6860\n",
      "Epoch 14/100\n",
      "605/605 [==============================] - 0s 141us/step - loss: 0.6169 - accuracy: 0.6694\n",
      "Epoch 15/100\n",
      "605/605 [==============================] - 0s 96us/step - loss: 0.6241 - accuracy: 0.6744\n",
      "Epoch 16/100\n",
      "605/605 [==============================] - 0s 108us/step - loss: 0.5957 - accuracy: 0.6860\n",
      "Epoch 17/100\n",
      "605/605 [==============================] - 0s 115us/step - loss: 0.5702 - accuracy: 0.6893\n",
      "Epoch 18/100\n",
      "605/605 [==============================] - 0s 129us/step - loss: 0.5930 - accuracy: 0.6496\n",
      "Epoch 19/100\n",
      "605/605 [==============================] - 0s 127us/step - loss: 0.5904 - accuracy: 0.6860\n",
      "Epoch 20/100\n",
      "605/605 [==============================] - 0s 130us/step - loss: 0.5579 - accuracy: 0.7124\n",
      "Epoch 21/100\n",
      "605/605 [==============================] - 0s 131us/step - loss: 0.5495 - accuracy: 0.7058\n",
      "Epoch 22/100\n",
      "605/605 [==============================] - 0s 141us/step - loss: 0.5738 - accuracy: 0.7041\n",
      "Epoch 23/100\n",
      "605/605 [==============================] - 0s 127us/step - loss: 0.5626 - accuracy: 0.7058\n",
      "Epoch 24/100\n",
      "605/605 [==============================] - 0s 137us/step - loss: 0.5454 - accuracy: 0.7240\n",
      "Epoch 25/100\n",
      "605/605 [==============================] - 0s 106us/step - loss: 0.5479 - accuracy: 0.7074\n",
      "Epoch 26/100\n",
      "605/605 [==============================] - 0s 145us/step - loss: 0.5579 - accuracy: 0.6942\n",
      "Epoch 27/100\n",
      "605/605 [==============================] - 0s 175us/step - loss: 0.5304 - accuracy: 0.7372\n",
      "Epoch 28/100\n",
      "605/605 [==============================] - 0s 116us/step - loss: 0.5288 - accuracy: 0.7306\n",
      "Epoch 29/100\n",
      "605/605 [==============================] - 0s 124us/step - loss: 0.5416 - accuracy: 0.7190\n",
      "Epoch 30/100\n",
      "605/605 [==============================] - 0s 139us/step - loss: 0.5344 - accuracy: 0.7289\n",
      "Epoch 31/100\n",
      "605/605 [==============================] - 0s 145us/step - loss: 0.5158 - accuracy: 0.7438\n",
      "Epoch 32/100\n",
      "605/605 [==============================] - 0s 172us/step - loss: 0.5308 - accuracy: 0.7306\n",
      "Epoch 33/100\n",
      "605/605 [==============================] - 0s 139us/step - loss: 0.5103 - accuracy: 0.7405\n",
      "Epoch 34/100\n",
      "605/605 [==============================] - 0s 107us/step - loss: 0.5174 - accuracy: 0.7372\n",
      "Epoch 35/100\n",
      "605/605 [==============================] - 0s 124us/step - loss: 0.5011 - accuracy: 0.7620\n",
      "Epoch 36/100\n",
      "605/605 [==============================] - 0s 168us/step - loss: 0.5041 - accuracy: 0.7570\n",
      "Epoch 37/100\n",
      "605/605 [==============================] - 0s 146us/step - loss: 0.5021 - accuracy: 0.7620\n",
      "Epoch 38/100\n",
      "605/605 [==============================] - 0s 160us/step - loss: 0.5003 - accuracy: 0.7455\n",
      "Epoch 39/100\n",
      "605/605 [==============================] - 0s 115us/step - loss: 0.4987 - accuracy: 0.7471\n",
      "Epoch 40/100\n",
      "605/605 [==============================] - 0s 139us/step - loss: 0.4965 - accuracy: 0.7603\n",
      "Epoch 41/100\n",
      "605/605 [==============================] - 0s 164us/step - loss: 0.4911 - accuracy: 0.7669\n",
      "Epoch 42/100\n",
      "605/605 [==============================] - 0s 136us/step - loss: 0.4845 - accuracy: 0.7702\n",
      "Epoch 43/100\n",
      "605/605 [==============================] - 0s 167us/step - loss: 0.4922 - accuracy: 0.7554\n",
      "Epoch 44/100\n",
      "605/605 [==============================] - 0s 94us/step - loss: 0.5028 - accuracy: 0.7504\n",
      "Epoch 45/100\n",
      "605/605 [==============================] - 0s 183us/step - loss: 0.4751 - accuracy: 0.7719\n",
      "Epoch 46/100\n",
      "605/605 [==============================] - 0s 150us/step - loss: 0.4878 - accuracy: 0.7620\n",
      "Epoch 47/100\n",
      "605/605 [==============================] - 0s 96us/step - loss: 0.4746 - accuracy: 0.7686\n",
      "Epoch 48/100\n",
      "605/605 [==============================] - 0s 154us/step - loss: 0.4785 - accuracy: 0.7769\n",
      "Epoch 49/100\n",
      "605/605 [==============================] - 0s 171us/step - loss: 0.4790 - accuracy: 0.7537\n",
      "Epoch 50/100\n",
      "605/605 [==============================] - 0s 110us/step - loss: 0.4744 - accuracy: 0.7686\n",
      "Epoch 51/100\n",
      "605/605 [==============================] - 0s 155us/step - loss: 0.4639 - accuracy: 0.7570\n",
      "Epoch 52/100\n",
      "605/605 [==============================] - 0s 158us/step - loss: 0.4709 - accuracy: 0.7570\n",
      "Epoch 53/100\n",
      "605/605 [==============================] - 0s 113us/step - loss: 0.4684 - accuracy: 0.7587\n",
      "Epoch 54/100\n",
      "605/605 [==============================] - 0s 144us/step - loss: 0.4736 - accuracy: 0.7636\n",
      "Epoch 55/100\n",
      "605/605 [==============================] - 0s 138us/step - loss: 0.4656 - accuracy: 0.7653\n",
      "Epoch 56/100\n",
      "605/605 [==============================] - 0s 134us/step - loss: 0.4638 - accuracy: 0.7934\n",
      "Epoch 57/100\n",
      "605/605 [==============================] - 0s 112us/step - loss: 0.4612 - accuracy: 0.7884\n",
      "Epoch 58/100\n",
      "605/605 [==============================] - 0s 159us/step - loss: 0.4681 - accuracy: 0.7686\n",
      "Epoch 59/100\n",
      "605/605 [==============================] - 0s 146us/step - loss: 0.4567 - accuracy: 0.7802\n",
      "Epoch 60/100\n",
      "605/605 [==============================] - 0s 155us/step - loss: 0.4586 - accuracy: 0.7702\n",
      "Epoch 61/100\n",
      "605/605 [==============================] - 0s 158us/step - loss: 0.4592 - accuracy: 0.7719\n",
      "Epoch 62/100\n",
      "605/605 [==============================] - 0s 129us/step - loss: 0.4607 - accuracy: 0.7785\n",
      "Epoch 63/100\n",
      "605/605 [==============================] - 0s 122us/step - loss: 0.4532 - accuracy: 0.7868\n",
      "Epoch 64/100\n",
      "605/605 [==============================] - 0s 104us/step - loss: 0.4575 - accuracy: 0.7785\n",
      "Epoch 65/100\n",
      "605/605 [==============================] - 0s 135us/step - loss: 0.4463 - accuracy: 0.7851\n",
      "Epoch 66/100\n",
      "605/605 [==============================] - 0s 134us/step - loss: 0.4490 - accuracy: 0.7769\n",
      "Epoch 67/100\n",
      "605/605 [==============================] - 0s 137us/step - loss: 0.4479 - accuracy: 0.7851\n",
      "Epoch 68/100\n",
      "605/605 [==============================] - 0s 136us/step - loss: 0.4511 - accuracy: 0.7802\n",
      "Epoch 69/100\n",
      "605/605 [==============================] - 0s 111us/step - loss: 0.4493 - accuracy: 0.7835\n",
      "Epoch 70/100\n",
      "605/605 [==============================] - 0s 109us/step - loss: 0.4578 - accuracy: 0.7818\n",
      "Epoch 71/100\n",
      "605/605 [==============================] - 0s 126us/step - loss: 0.4471 - accuracy: 0.7702\n",
      "Epoch 72/100\n",
      "605/605 [==============================] - 0s 114us/step - loss: 0.4418 - accuracy: 0.7917\n",
      "Epoch 73/100\n",
      "605/605 [==============================] - 0s 164us/step - loss: 0.4518 - accuracy: 0.7785\n",
      "Epoch 74/100\n",
      "605/605 [==============================] - 0s 169us/step - loss: 0.4519 - accuracy: 0.7603\n",
      "Epoch 75/100\n",
      "605/605 [==============================] - 0s 177us/step - loss: 0.4531 - accuracy: 0.7702\n",
      "Epoch 76/100\n",
      "605/605 [==============================] - 0s 170us/step - loss: 0.4324 - accuracy: 0.7901\n",
      "Epoch 77/100\n",
      "605/605 [==============================] - 0s 215us/step - loss: 0.4377 - accuracy: 0.7785\n",
      "Epoch 78/100\n",
      "605/605 [==============================] - 0s 141us/step - loss: 0.4301 - accuracy: 0.7851\n",
      "Epoch 79/100\n",
      "605/605 [==============================] - 0s 160us/step - loss: 0.4428 - accuracy: 0.7785\n",
      "Epoch 80/100\n",
      "605/605 [==============================] - 0s 190us/step - loss: 0.4491 - accuracy: 0.7702\n",
      "Epoch 81/100\n",
      "605/605 [==============================] - 0s 226us/step - loss: 0.4513 - accuracy: 0.7769\n",
      "Epoch 82/100\n",
      "605/605 [==============================] - 0s 201us/step - loss: 0.4361 - accuracy: 0.7934\n",
      "Epoch 83/100\n",
      "605/605 [==============================] - 0s 183us/step - loss: 0.4456 - accuracy: 0.7868\n",
      "Epoch 84/100\n",
      "605/605 [==============================] - 0s 92us/step - loss: 0.4487 - accuracy: 0.7901\n",
      "Epoch 85/100\n",
      "605/605 [==============================] - 0s 144us/step - loss: 0.4392 - accuracy: 0.7785\n",
      "Epoch 86/100\n",
      "605/605 [==============================] - 0s 126us/step - loss: 0.4318 - accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "605/605 [==============================] - 0s 105us/step - loss: 0.4413 - accuracy: 0.7669\n",
      "Epoch 88/100\n",
      "605/605 [==============================] - 0s 162us/step - loss: 0.4451 - accuracy: 0.7686\n",
      "Epoch 89/100\n",
      "605/605 [==============================] - 0s 125us/step - loss: 0.4405 - accuracy: 0.7884\n",
      "Epoch 90/100\n",
      "605/605 [==============================] - 0s 132us/step - loss: 0.4372 - accuracy: 0.7736\n",
      "Epoch 91/100\n",
      "605/605 [==============================] - 0s 112us/step - loss: 0.4243 - accuracy: 0.8099\n",
      "Epoch 92/100\n",
      "605/605 [==============================] - 0s 133us/step - loss: 0.4243 - accuracy: 0.8050\n",
      "Epoch 93/100\n",
      "605/605 [==============================] - 0s 126us/step - loss: 0.4240 - accuracy: 0.7917\n",
      "Epoch 94/100\n",
      "605/605 [==============================] - 0s 123us/step - loss: 0.4438 - accuracy: 0.7884\n",
      "Epoch 95/100\n",
      "605/605 [==============================] - 0s 107us/step - loss: 0.4285 - accuracy: 0.8050\n",
      "Epoch 96/100\n",
      "605/605 [==============================] - 0s 138us/step - loss: 0.4308 - accuracy: 0.8033\n",
      "Epoch 97/100\n",
      "605/605 [==============================] - 0s 169us/step - loss: 0.4295 - accuracy: 0.7868\n",
      "Epoch 98/100\n",
      "605/605 [==============================] - 0s 138us/step - loss: 0.4354 - accuracy: 0.7967\n",
      "Epoch 99/100\n",
      "605/605 [==============================] - 0s 180us/step - loss: 0.4303 - accuracy: 0.7967\n",
      "Epoch 100/100\n",
      "605/605 [==============================] - 0s 174us/step - loss: 0.4366 - accuracy: 0.7769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe95ba9cc90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_data, train_label, epochs = 100, batch_size = 605)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treino, nossa rede neural acertou 77.7% das vezes. Legal, vamos agora testar o modelo nos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 3ms/step\n",
      "test_acc =  0.7631579041481018\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc  = network.evaluate(test_data, test_label)\n",
    "print('test_acc = ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o teste, a rede neural acertou 76.3% dos resultados!\n",
    "\n",
    "Uma outra forma de observarmos o desempenho da nossa rede é através da curva ROC. ROC quer dizer Reciever Operating Characteristic, e a curva ROC nos da a performance do nosso modelo em termos de dois parâmetros, a taxa de falso positivos (FPR) e a taxa de verdadeiros positivos (TPR).\n",
    "\n",
    "Cada um deles é calculado da seguinte forma\n",
    "\n",
    "$$TPR = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "$$FPR = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "A área embaixo da curva ROC nos da a porcentagem de previsões corretas pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC curve')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = network.predict(test_data) #gera previsões para os dados de teste\n",
    "\n",
    "th = np.linspace(0, 1, 100) #crio um threshold the classificação que vai variar\n",
    "\n",
    "def ROC(th, pred, test_label):\n",
    "    FPR = np.zeros(len(th))\n",
    "    TPR = np.zeros(len(th))\n",
    "    \n",
    "    N = pred[np.where(test_label == 0)]\n",
    "    P = pred[np.where(test_label == 1)]\n",
    "    \n",
    "    for i in range(len(th)):\n",
    "        FN = len(np.where(P <= th[i])[0])\n",
    "        FP = len(np.where(N > th[i])[0])\n",
    "        TN = len(np.where(N <= th[i])[0])\n",
    "        TP = len(np.where(P > th[i])[0])\n",
    "        \n",
    "        FPR[i] = FP/(FP + TN)\n",
    "        TPR[i] = TP/(TP + FN)\n",
    "        \n",
    "        result = np.concatenate((FPR, TPR)).reshape(2, len(th))\n",
    "        \n",
    "    return result[np.argsort(result[:,0])]\n",
    "\n",
    "plt.grid(True, alpha = 0.4)\n",
    "plt.plot(*ROC(th, pred, test_label), color = 'blue')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área da curva:  0.8391179839633448\n"
     ]
    }
   ],
   "source": [
    "roc = ROC(th, pred, test_label).T\n",
    "\n",
    "# Exclui valores repetidos para a integração\n",
    "r = roc[:1]\n",
    "for i in range(1,len(roc)):\n",
    "\n",
    "  if (roc[i,0] != roc[i-1,0]):\n",
    "\n",
    "    r = np.append(r, roc[i])\n",
    "\n",
    "# Curva ROC sem valores repetidos\n",
    "roc = r.reshape((np.int(len(r)/2), 2))\n",
    "\n",
    "S = -simps(roc[:,1], roc[:,0])\n",
    "print('Área da curva: ', S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[1]. World Health Organization, Health Topics, Diabetes. https://www.who.int/health-topics/diabetes#tab=tab_1\n",
    "\n",
    "[2]. Machine Learning Crash Course, Google. https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
